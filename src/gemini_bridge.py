import google.generativeai as genai
import os
import argparse
from pathlib import Path
from dotenv import load_dotenv
import sys
import pandas as pd
from datetime import datetime
import json

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from src.data_pipeline import load_config
from myKiteLib import kiteAPIs, system_initialization

# Load environment variables from .env file
load_dotenv()

try:
    # Load the API key and model name from environment variables
    api_key = os.environ["GEMINI_API_KEY"]
    MODEL_NAME = os.environ["MODEL_NAME"]
except KeyError as e:
    print(f"Error: The environment variable '{e.args[0]}' is not set.")
    print("Please make sure your .env file is configured correctly with GEMINI_API_KEY and MODEL_NAME.")
    exit()

genai.configure(api_key=api_key)

# Use the latest "flash" model, which is fast and versatile.
# For other available models, see: https://ai.google.dev/models/gemini


def get_opinion(tradingsymbol):
    """Generates content using the Gemini API."""
    prompt = f"""You are a financial analyst providing a second opinion on a trading signal.

    CONTEXT:
    - Market: NSE (Indian Stock Market)
    - Trading Symbol: {tradingsymbol}
    - Signal: BUY (generated by ML algorithm)
    - Timeframe: Short to medium term (7 days)

    TASK:
    Analyze whether you agree with this BUY signal based on:
    1. Recent market trends and sector performance
    2. Company fundamentals and recent news
    3. Technical indicators and market sentiment
    4. Overall market conditions

    RESPONSE FORMAT:
    Return a valid JSON object with this exact structure:
    {{
        "opinion": "Agree|Disagree|Neutral",
        "confidence": "High|Medium|Low",
        "reasoning": "Your analysis in 80-120 words explaining the key factors",
        "risk_factors": "Main risks to consider (30-50 words)",
    }}

    GUIDELINES:
    - Base analysis on current market data and recent trends
    - Be objective and consider both bullish and bearish factors
    - Focus on actionable insights
    - If data is insufficient, use "Neutral" with explanation

    Provide your analysis now:"""

    try:
        model = genai.GenerativeModel('gemini-2.5-pro')
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        print(f"An error occurred during content generation: {e}")
        return None

def save_to_file(content, output_file):
    """Saves the given content to a text file."""
    try:
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(content)
        print(f"Successfully saved the response to '{output_file}'")
    except IOError as e:
        print(f"Error saving to file: {e}")

def main():
    """Main function to run the Gemini bridge script."""
    parser = argparse.ArgumentParser(
        description="A bridge to the Gemini API to generate content from markdown files."
    )
    parser.add_argument(
        "-o",
        "--output",
        default="trades.txt",
        help="The name of the output file to save the response (default: output.txt).",
    )
    args = parser.parse_args()

    # The markdown files are now hardcoded
    
    config = load_config('config/parameters.yml')
    data_config = config.get('data', {})
    data_end_date = data_config.get('test_end_date', datetime.now().strftime('%Y-%m-%d'))
    
    signals_df = pd.read_csv('reports/trades/daily_trades.csv')
    signals_df = signals_df[signals_df['Action'] == 'SIGNAL_NO_EXECUTION']
    token_list = signals_df[signals_df['Date'] == data_end_date]['Instrument_Token'].unique()
    tradingsymbol = []
    print(token_list)


    systemDetails = system_initialization()
    for token in token_list:
        result = systemDetails.run_query_limit(f"Select tradingsymbol from kiteconnect.instruments_zerodha where instrument_token = {token}")
        tradingsymbol.append(result[0])
        
    print(f"Result: {tradingsymbol}")

    # Collect all results in an array
    all_results = []
    
    for symbol in tradingsymbol:
        generated_content = get_opinion(symbol)
        
        if generated_content:
            try:
                # Clean the response - sometimes LLM adds extra text before/after JSON
                content = generated_content.strip()
                
                # Find JSON block if it's wrapped in markdown code blocks
                if "```json" in content:
                    start = content.find("```json") + 7
                    end = content.find("```", start)
                    if end != -1:
                        content = content[start:end].strip()
                
                # Find JSON object boundaries if there's extra text
                elif content.startswith('{') and content.endswith('}'):
                    pass  # Already clean JSON
                else:
                    # Try to find JSON object in the response
                    start = content.find('{')
                    end = content.rfind('}') + 1
                    if start != -1 and end > start:
                        content = content[start:end]
                
                # Parse the JSON response from LLM
                opinion_data = json.loads(content)
                
                # Add the tradingsymbol to the JSON object
                opinion_data['tradingsymbol'] = symbol
                
                # Add to results array
                all_results.append(opinion_data)
                
            except json.JSONDecodeError as e:
                # Add error entry with actual error details
                all_results.append({
                    "tradingsymbol": symbol,
                    "opinion": "Error", 
                    "confidence": "N/A",
                    "reasoning": f"Failed to parse LLM response: {str(e)}",
                    "risk_factors": "Invalid response format from LLM"
                })
            except Exception as e:
                all_results.append({
                    "tradingsymbol": symbol,
                    "opinion": "Error",
                    "confidence": "N/A", 
                    "reasoning": f"Unexpected error: {str(e)}",
                    "risk_factors": "Processing error"
                })
        else:
            all_results.append({
                "tradingsymbol": symbol,
                "opinion": "Error",
                "confidence": "N/A",
                "reasoning": "No response generated from LLM",
                "risk_factors": "API call failed"
            })
    
    # Save all results as JSON array to file
    if all_results:
        save_to_file(json.dumps(all_results, indent=2), args.output)



if __name__ == "__main__":
    main() 